# app.py

import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search

st.set_page_config(page_title="Semantic Assistant", layout="centered")
st.title("ü§ñ Semantic Assistant")

@st.cache_data
def get_data():
    df = load_all_excels()
    from utils import get_model
    model = get_model()
    df.attrs['phrase_embs'] = model.encode(df['phrase_proc'].tolist(), convert_to_tensor=True)
    return df

df = get_data()

# üîò –í—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º–∞—Ç–∏–∫–∏
all_topics = sorted({topic for topics in df['topics'] for topic in topics})
selected_topics = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–∏—Å–∫–∞):", all_topics)

# üìå –ù–µ–∑–∞–≤–∏—Å–∏–º–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–º–∞–º
if selected_topics:
    st.markdown("### üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º:")
    filtered_df = df[df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))]
    for row in filtered_df.itertuples():
        st.markdown(f"- **{row.phrase_full}** ‚Üí {', '.join(row.topics)}")
        if row.comment and str(row.comment).strip().lower() != "nan":
            with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                st.markdown(row.comment)

# üì• –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:")

if query:
    try:
        results = semantic_search(query, df)
        if results:
            st.markdown("### üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
            for score, phrase_full, topics, comment in results:
                st.markdown(f"**{phrase_full}** ‚Üí {', '.join(topics)} (_{score:.2f}_)")
                if comment and str(comment).strip().lower() != "nan":
                    with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                        st.markdown(comment)
                st.markdown("<hr style='margin:4px 0' />", unsafe_allow_html=True)
        else:
            st.warning("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —É–º–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

        exact_results = keyword_search(query, df)
        if exact_results:
            st.markdown("### üß∑ –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫:")
            for phrase, topics, comment in exact_results:
                st.markdown(f"**{phrase}** ‚Üí {', '.join(topics)}")
                if comment and str(comment).strip().lower() != "nan":
                    with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                        st.markdown(comment)
                st.markdown("<hr style='margin:4px 0' />", unsafe_allow_html=True)
        else:
            st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–æ—á–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
