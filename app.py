import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
import functools

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (Flan-T5-small) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_resource
def load_llm():
    model_name = "google/flan-t5-small"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    return pipeline("text2text-generation", model=model, tokenizer=tokenizer)

# ‚îÄ‚îÄ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–∞–∑—ã ‚îÄ‚îÄ
@st.cache_data
def load_data():
    return load_all_excels()

st.set_page_config(page_title="Chat + Semantic Search", layout="wide")
st.title("üí¨ –ß–∞—Ç‚Äë–±–æ—Ç + Semantic Search")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
llm = load_llm()
df = load_data()
if "history" not in st.session_state:
    st.session_state.history = []

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞
for role, msg in st.session_state.history:
    with st.chat_message(role):
        st.markdown(msg)

# –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
prompt = st.chat_input("–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")

if prompt:
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
    st.session_state.history.append(("user", prompt))
    with st.chat_message("assistant"):
        st.markdown("ü§ñ –î—É–º–∞—é‚Ä¶")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è LLM
    response = llm(prompt, max_new_tokens=100)[0]["generated_text"]
    st.session_state.history.pop()  # —É–±–∏—Ä–∞–µ–º "–î—É–º–∞—é..."
    st.session_state.history.append(("assistant", response))

    # Semantic search
    sem = semantic_search(prompt, df, top_k=3, threshold=0.5)
    kw = keyword_search(prompt, df)

    combined = []
    if sem:
        for s, phrase, topics, comment in sem:
            combined.append(f"üîπ {phrase} (_{', '.join(topics)}_) ‚Äî {s:.2f}")
    elif kw:
        for phrase, topics, comment in kw:
            combined.append(f"üî∏ {phrase} (_{', '.join(topics)}_)")
    else:
        combined.append("‚ö†Ô∏è –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ.")

    combined_txt = "\n\n".join(combined)
    st.session_state.history.append(("assistant", combined_txt))

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç—ã (LLM + –±–∞–∑–∞)
    for role, msg in st.session_state.history[-2:]:
        with st.chat_message(role):
            st.markdown(msg)
