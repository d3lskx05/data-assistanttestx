import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search, get_model
import torch  # –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏

st.set_page_config(page_title="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑ –§–õ", layout="centered")
st.title("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑")

@st.cache_data
def get_data():
    df = load_all_excels()
    model = get_model()
    df.attrs['phrase_embs'] = model.encode(df['phrase_proc'].tolist(), convert_to_tensor=True)
    return df

df = get_data()

# üîò –í—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º–∞—Ç–∏–∫–∏
all_topics = sorted({topic for topics in df['topics'] for topic in topics})
selected_topics = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–∏—Å–∫–∞):", all_topics)
filter_search_by_topics = st.checkbox("–ò—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–µ–º–∞—Ç–∏–∫–∞—Ö", value=False)

# üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º
if selected_topics:
    st.markdown("### üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º:")
    filtered_df = df[df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))]
    for row in filtered_df.itertuples():
        with st.container():
            st.markdown(
                f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                    <div style="font-size: 18px; font-weight: 600; color: #333;">üìù {row.phrase_full}</div>
                    <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(row.topics)}</strong></div>
                </div>""",
                unsafe_allow_html=True
            )
            if row.comment and str(row.comment).strip().lower() != "nan":
                with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                    st.markdown(row.comment)

# üì• –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:")

if query:
    try:
        search_df = df
        if filter_search_by_topics and selected_topics:
            mask = df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))
            search_df = df[mask]

            # –°–æ–≥–ª–∞—Å—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º DF
            full_embs = df.attrs.get('phrase_embs', None)
            if full_embs is not None:
                indices = search_df.index.tolist()
                if isinstance(full_embs, torch.Tensor):
                    if indices:
                        search_df.attrs['phrase_embs'] = full_embs[indices]
                    else:
                        search_df.attrs['phrase_embs'] = full_embs.new_empty((0, full_embs.size(1)))
                else:
                    import numpy as np
                    arr = np.asarray(full_embs)
                    search_df.attrs['phrase_embs'] = arr[indices]

        if search_df.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º.")
        else:
            results = semantic_search(query, search_df)
            if results:
                st.markdown("### üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
                for score, phrase_full, topics, comment in results:
                    with st.container():
                        st.markdown(
                            f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                                <div style="font-size: 18px; font-weight: 600; color: #333;">üß† {phrase_full}</div>
                                <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics)}</strong></div>
                                <div style="margin-top: 2px; font-size: 13px; color: #999;">üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.2f}</div>
                            </div>""",
                            unsafe_allow_html=True
                        )
                        if comment and str(comment).strip().lower() != "nan":
                            with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                                st.markdown(comment)
            else:
                st.warning("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —É–º–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

            exact_results = keyword_search(query, search_df)
            if exact_results:
                st.markdown("### üß∑ –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫:")
                for phrase, topics, comment in exact_results:
                    with st.container():
                        st.markdown(
                            f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                                <div style="font-size: 18px; font-weight: 600; color: #333;">üìå {phrase}</div>
                                <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics)}</strong></div>
                            </div>""",
                            unsafe_allow_html=True
                        )
                        if comment and str(comment).strip().lower() != "nan":
                            with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                                st.markdown(comment)
            else:
                st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–æ—á–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
